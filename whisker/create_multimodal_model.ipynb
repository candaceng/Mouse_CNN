{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH set to: c:\\Users\\canda\\Documents\\mousenet\\Mouse_CNN\\mousenet\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "repo_root = os.path.abspath(os.path.join(\"..\"))\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "print(\"PYTHONPATH set to:\", repo_root)\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../cmouse/')\n",
    "sys.path.append('../mouse_cnn/')\n",
    "from anatomy import *\n",
    "from architecture import *\n",
    "%matplotlib inline\n",
    "\n",
    "from config import *\n",
    "# from network import Network\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "from whisker.multimodal_model_pool import MultimodalMouseModelPool\n",
    "# from network import save_network_to_pickle\n",
    "from network import load_network_from_pickle\n",
    "from whisker.preprocess_dataset import PreprocessedTrialDataset\n",
    "\n",
    "from mousenet_complete_pool import MouseNetCompletePool\n",
    "from whisker.clip_train import clip_loss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9780a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputLGNd': (0, 64, 0, 64), 'LGNdVISp4': (0, 64, 0, 51), 'VISp4VISp2/3': (0, 78, 0, 50), 'VISp4VISl4': (0, 48, 12, 38), 'VISp4VISrl4': (0, 61, 0, 45), 'VISp4VISli4': (8, 42, 6, 44), 'VISp4VISpl4': (9, 69, 19, 31), 'VISp4VISal4': (7, 46, 10, 34), 'VISp4VISpor4': (9, 38, 19, 25), 'VISp2/3VISp5': (0, 78, 0, 50), 'VISp2/3VISl4': (0, 48, 12, 38), 'VISp2/3VISrl4': (0, 61, 0, 45), 'VISp2/3VISli4': (9, 40, 7, 43), 'VISp2/3VISpl4': (9, 69, 19, 31), 'VISp2/3VISal4': (8, 44, 11, 32), 'VISp2/3VISpor4': (9, 38, 19, 25), 'VISl4VISl2/3': (0, 39, 0, 26), 'VISl4VISpor4': (10, 29, 0, 22), 'VISrl4VISrl2/3': (0, 48, 0, 36), 'VISrl4VISpor4': (8, 32, 22, 14), 'VISli4VISli2/3': (0, 24, 0, 34), 'VISli4VISpor4': (0, 24, 4, 25), 'VISpl4VISpl2/3': (0, 61, 0, 23), 'VISpl4VISpor4': (0, 23, 0, 10), 'VISal4VISal2/3': (0, 30, 0, 18), 'VISal4VISpor4': (1, 24, 8, 10), 'VISpor4VISpor2/3': (0, 22, 0, 9), 'VISp5VISl4': (0, 48, 12, 38), 'VISp5VISrl4': (0, 61, 0, 45), 'VISp5VISli4': (8, 42, 6, 44), 'VISp5VISpl4': (9, 69, 19, 31), 'VISp5VISal4': (8, 44, 11, 32), 'VISp5VISpor4': (8, 40, 18, 27), 'VISl2/3VISl5': (0, 39, 0, 26), 'VISl2/3VISpor4': (10, 29, 0, 22), 'VISrl2/3VISrl5': (0, 48, 0, 36), 'VISrl2/3VISpor4': (8, 32, 22, 14), 'VISli2/3VISli5': (0, 24, 0, 34), 'VISli2/3VISpor4': (0, 24, 5, 23), 'VISpl2/3VISpl5': (0, 61, 0, 23), 'VISpl2/3VISpor4': (0, 24, 0, 11), 'VISal2/3VISal5': (0, 30, 0, 18), 'VISal2/3VISpor4': (2, 22, 9, 9), 'VISpor2/3VISpor5': (0, 22, 0, 9), 'VISl5VISpor4': (10, 29, 0, 22), 'VISrl5VISpor4': (8, 32, 22, 14), 'VISli5VISpor4': (0, 24, 6, 21), 'VISpl5VISpor4': (0, 24, 0, 11), 'VISal5VISpor4': (2, 22, 9, 9)}\n"
     ]
    }
   ],
   "source": [
    "# architecture = Architecture()\n",
    "# anet = gen_anatomy(architecture)\n",
    "\n",
    "# network = Network()\n",
    "# network.construct_from_anatomy(anet, architecture)\n",
    "# save_network_to_pickle(network, 'network_test.pkl')\n",
    "\n",
    "network = load_network_from_pickle('network_test.pkl')\n",
    "visual_net = MouseNetCompletePool(network)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalMouseModelPool(visual_net=visual_net).to(device)\n",
    "\n",
    "preprocess_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae267c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess_dataset:    \n",
    "    zipped_dir = Path(r'C:\\Users\\canda\\MouseNet\\Assets\\RecordedTrials')\n",
    "    temp_dir = Path(\"temp_extract\")  \n",
    "    output_dir = Path(\"PreprocessedTrials\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for zip_path in sorted(zipped_dir.glob(\"batch_*.zip\")):\n",
    "        print(f\"üì¶ Processing {zip_path.name}\")\n",
    "        # Extract to temp\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "\n",
    "        for trial_dir in temp_dir.glob(\"trial_*\"):\n",
    "            if not trial_dir.is_dir():\n",
    "                continue  # Skip .meta or other non-directories\n",
    "            try:\n",
    "                # Load and preprocess image\n",
    "                image_path = trial_dir / \"frame_0000.png\"\n",
    "                image = Image.open(image_path).convert(\"L\").resize((64, 64))\n",
    "                image_tensor = torch.tensor(np.array(image) / 255.0, dtype=torch.float32).unsqueeze(0)  # [1, 60, 60]\n",
    "\n",
    "                # Load whisker CSVs\n",
    "                whisker_data = []\n",
    "                for csv_file in sorted(trial_dir.glob(\"R*.csv\")):\n",
    "                    df = pd.read_csv(csv_file, header=None).to_numpy()  # [15, 4]\n",
    "                    whisker_data.append(df)\n",
    "\n",
    "                whisker_tensor = torch.tensor(np.stack(whisker_data), dtype=torch.float32)  # [60, 15, 4]\n",
    "\n",
    "                # Save to .pt\n",
    "                trial_id = trial_dir.name.replace(\"trial_\", \"\")\n",
    "                save_path = output_dir / f\"trial_{trial_id}.pt\"\n",
    "                torch.save((image_tensor, whisker_tensor), save_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to process {trial_dir}: {e}\")\n",
    "\n",
    "        # Clean up temp folder\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "    print(\"‚úÖ Done processing all zipped batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8101d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PreprocessedTrialDataset(\"PreprocessedTrials\")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,   \n",
    "    pin_memory=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635ea7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 3.2397, œÑ = 0.1978\n",
      "Epoch 2: Loss = 2.9374, œÑ = 0.1964\n",
      "Epoch 3: Loss = 2.7923, œÑ = 0.1950\n",
      "Epoch 4: Loss = 2.6618, œÑ = 0.1931\n",
      "Epoch 5: Loss = 2.5531, œÑ = 0.1907\n",
      "Epoch 6: Loss = 2.4584, œÑ = 0.1882\n",
      "Epoch 7: Loss = 2.3741, œÑ = 0.1852\n",
      "Epoch 8: Loss = 2.3049, œÑ = 0.1822\n",
      "Epoch 9: Loss = 2.2130, œÑ = 0.1790\n",
      "Epoch 10: Loss = 2.1250, œÑ = 0.1755\n",
      "Epoch 11: Loss = 2.0473, œÑ = 0.1722\n",
      "Epoch 12: Loss = 1.9648, œÑ = 0.1688\n",
      "Epoch 13: Loss = 1.8679, œÑ = 0.1654\n",
      "Epoch 14: Loss = 1.7830, œÑ = 0.1620\n",
      "Epoch 15: Loss = 1.6948, œÑ = 0.1587\n",
      "Epoch 16: Loss = 1.6103, œÑ = 0.1555\n",
      "Epoch 17: Loss = 1.4976, œÑ = 0.1523\n",
      "Epoch 18: Loss = 1.4179, œÑ = 0.1492\n",
      "Epoch 19: Loss = 1.3413, œÑ = 0.1462\n",
      "Epoch 20: Loss = 1.2355, œÑ = 0.1433\n",
      "Epoch 21: Loss = 1.1878, œÑ = 0.1406\n",
      "Epoch 22: Loss = 1.0866, œÑ = 0.1379\n",
      "Epoch 23: Loss = 1.0260, œÑ = 0.1354\n",
      "Epoch 24: Loss = 0.9538, œÑ = 0.1329\n",
      "Epoch 25: Loss = 0.8947, œÑ = 0.1306\n",
      "Epoch 26: Loss = 0.8433, œÑ = 0.1284\n",
      "Epoch 27: Loss = 0.8146, œÑ = 0.1263\n",
      "Epoch 28: Loss = 0.7826, œÑ = 0.1242\n",
      "Epoch 29: Loss = 0.6982, œÑ = 0.1222\n",
      "Epoch 30: Loss = 0.6647, œÑ = 0.1203\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "lr = 1e-4\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# --- Model and Optimizer ---\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# --- Logging ---\n",
    "tau_log = []\n",
    "loss_log = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for images, whiskers in dataloader:\n",
    "        images, whiskers = images.to(device), whiskers.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        z_v, z_w = model(images, whiskers)\n",
    "        temp = model.temperature  # already clamped\n",
    "        loss = clip_loss(z_v, z_w, temperature=temp)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    tau_value = model.temperature.item()\n",
    "\n",
    "    # Logging\n",
    "    tau_log.append(tau_value)\n",
    "    loss_log.append(avg_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}, œÑ = {tau_value:.4f}\")\n",
    "\n",
    "# Save model and results\n",
    "model_path = f\"models/model_learnable_temp.pt\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "model.eval()\n",
    "all_z_v, all_z_w = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, whisker in dataloader:\n",
    "        z_v, z_w = model(img.to(device), whisker.to(device))\n",
    "        all_z_v.append(z_v.cpu())\n",
    "        all_z_w.append(z_w.cpu())\n",
    "\n",
    "torch.save({\n",
    "    'z_v': torch.cat(all_z_v, dim=0),\n",
    "    'z_w': torch.cat(all_z_w, dim=0),\n",
    "    'temperature': model.temperature.item()  # or model.log_temp.exp().item()\n",
    "}, 'embeddings/embeddings_learnable_temp.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc999c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs/tau_tracking.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"tau\": tau_log,\n",
    "        \"loss\": loss_log\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d9e58d",
   "metadata": {},
   "source": [
    "### old code - training with fixed values of temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c7c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_temperature(temp):\n",
    "    print(f\"Training with temperature={temp}\")\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, whiskers in dataloader:\n",
    "            images, whiskers = images.to(device), whiskers.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            z_v, z_w = model(images, whiskers)\n",
    "            loss = clip_loss(z_v, z_w, temperature=temp)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "    # Save model and results\n",
    "    model_path = f\"models/model_temp_{temp:.2f}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    model.eval()\n",
    "    all_z_v, all_z_w = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, whisker in dataloader:\n",
    "            z_v, z_w = model(img.to(device), whisker.to(device))\n",
    "            all_z_v.append(z_v.cpu())\n",
    "            all_z_w.append(z_w.cpu())\n",
    "\n",
    "    torch.save({\n",
    "        'z_v': torch.cat(all_z_v, dim=0),\n",
    "        'z_w': torch.cat(all_z_w, dim=0)\n",
    "    }, f'embeddings/embeddings_temp_{temp:.2f}.pt')\n",
    "\n",
    "for temp in [0.15, 0.2]:\n",
    "    model = MultimodalMouseModelPool(visual_net=visual_net).to(device)  # Re-initialize for each temperature\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_with_temperature(temp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mousenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
